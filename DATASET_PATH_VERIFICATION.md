# Dataset Path Verification Report
## BitGen Multi-Dataset Training - Path Alignment Analysis

**Date**: 2025-10-15  
**Status**: ‚ö†Ô∏è **CRITICAL PATH MISMATCHES FOUND**

---

## üîç Analysis Summary

After analyzing both download scripts and the entire BitGen codebase, I've found **critical path mismatches** that will prevent training from working correctly after downloads complete.

---

## üì¶ Download Script Outputs

### 1. `download_coco_dataset.py`
**Output Directory**: `data/coco/`

**Expected Structure**:
```
data/coco/
‚îú‚îÄ‚îÄ validated_coco.json          # ‚úÖ Created by script
‚îú‚îÄ‚îÄ coco_verification_grid.png   # ‚úÖ Visualization
‚îî‚îÄ‚îÄ [images from Kaggle]         # ‚ö†Ô∏è UNKNOWN STRUCTURE
```

**Issues**:
- ‚ùå Kaggle dataset structure is **unknown** - script doesn't document what folders Kaggle creates
- ‚ùå No `annotations/` folder created
- ‚ùå No `train2017/` or `val2017/` folders guaranteed
- ‚ùå Script processes whatever Kaggle gives, but doesn't standardize structure

### 2. `download_fiber_datasets.py`
**Output Directory**: `data/`

**Expected Structure**:
```
data/
‚îú‚îÄ‚îÄ visual_genome/
‚îÇ   ‚îú‚îÄ‚îÄ VG_100K/                 # ‚úÖ Images folder 1
‚îÇ   ‚îú‚îÄ‚îÄ VG_100K_2/               # ‚úÖ Images folder 2
‚îÇ   ‚îú‚îÄ‚îÄ region_descriptions.json # ‚úÖ Captions
‚îÇ   ‚îî‚îÄ‚îÄ objects.json             # ‚úÖ Bounding boxes
‚îÇ
‚îú‚îÄ‚îÄ mdetr_annotations/
‚îÇ   ‚îú‚îÄ‚îÄ final_refcoco_train.json   # ‚úÖ RefCOCO
‚îÇ   ‚îú‚îÄ‚îÄ final_refcoco+_train.json  # ‚úÖ RefCOCO+
‚îÇ   ‚îî‚îÄ‚îÄ final_refcocog_train.json  # ‚úÖ RefCOCOg
‚îÇ
‚îú‚îÄ‚îÄ sbu/
‚îÇ   ‚îî‚îÄ‚îÄ README.txt               # ‚úÖ Manual download instructions
‚îÇ
‚îî‚îÄ‚îÄ conceptual_captions/
    ‚îî‚îÄ‚îÄ README.txt               # ‚úÖ Manual download instructions
```

---

## üéØ Training Code Expectations

### `src/multi_dataset_loader.py` - EXACT Path Requirements

#### **COCOCaptionDataset** (Lines 76-88)
```python
# EXPECTS:
if split == "train":
    ann_file = self.data_root / "coco" / "annotations" / "captions_train2017.json"
    image_dir = self.data_root / "coco" / "train2017"
elif split == "val":
    ann_file = self.data_root / "coco" / "annotations" / "captions_val2017.json"
    image_dir = self.data_root / "coco" / "val2017"
```

**‚ùå PROBLEM**: 
- `download_coco_dataset.py` does **NOT** create `annotations/` folder
- `download_coco_dataset.py` does **NOT** guarantee `train2017/` or `val2017/` folders
- Kaggle dataset has **unknown structure** - might be flat or have different naming

**‚úÖ WORKS**: Visual Genome paths match perfectly

#### **VisualGenomeCaptionDataset** (Lines 147-151)
```python
# EXPECTS:
ann_file = self.data_root / "visual_genome" / "region_descriptions.json"
image_dirs = [
    self.data_root / "visual_genome" / "VG_100K",
    self.data_root / "visual_genome" / "VG_100K_2"
]
```

**‚úÖ MATCH**: `download_fiber_datasets.py` creates exactly these paths

#### **RefCOCODataset** (Lines 228-230)
```python
# EXPECTS:
ann_file = self.data_root / "mdetr_annotations" / f"final_{dataset_name}_train.json"
image_dir = self.data_root / "coco" / "train2014"
```

**‚ùå CRITICAL PROBLEM**:
- RefCOCO needs **COCO 2014 images** (`train2014/` folder)
- `download_coco_dataset.py` downloads from Kaggle (likely 2017 split)
- **Path mismatch**: Training expects `train2014/`, COCO downloader creates unknown structure

#### **VisualGenomeRegionDataset** (Lines 311-313)
```python
# EXPECTS:
ann_file = self.data_root / "visual_genome" / "objects.json"
image_dirs = [
    self.data_root / "visual_genome" / "VG_100K",
    self.data_root / "visual_genome" / "VG_100K_2"
]
```

**‚úÖ MATCH**: `download_fiber_datasets.py` creates exactly these paths

---

## üö® Critical Issues Found

### Issue #1: COCO 2017 vs 2014 Mismatch
**Severity**: üî¥ **CRITICAL** - RefCOCO training will fail

**Problem**:
- `RefCOCODataset` expects: `data/coco/train2014/`
- `download_coco_dataset.py` downloads: Kaggle dataset (likely 2017 or unknown structure)
- RefCOCO annotations reference COCO 2014 image IDs

**Impact**:
- Phase 2 (fine-grained) training will **fail** - no images found
- RefCOCO/+/g datasets will have 0 samples loaded

**Fix Required**:
```python
# download_coco_dataset.py needs to:
# 1. Download COCO 2014 images (train2014/, val2014/)
# 2. OR: download_fiber_datasets.py should download COCO 2014 separately
```

### Issue #2: COCO Annotations Folder Missing
**Severity**: üü° **MAJOR** - COCO training might fail

**Problem**:
- `COCOCaptionDataset` expects: `data/coco/annotations/captions_train2017.json`
- `download_coco_dataset.py` creates: `data/coco/validated_coco.json` (custom format)
- Training code expects **COCO JSON format** with separate annotations folder

**Impact**:
- If using `use_multi_datasets=True`, COCO loader will fail
- Legacy mode (single dataset) might still work with `validated_coco.json`

**Fix Required**:
```python
# Option 1: Update multi_dataset_loader.py to use validated_coco.json
# Option 2: Update download_coco_dataset.py to create proper structure
```

### Issue #3: Unknown Kaggle Dataset Structure
**Severity**: üü° **MAJOR** - Unpredictable failures

**Problem**:
- `download_coco_dataset.py` downloads from Kaggle without verifying structure
- Training code assumes specific folder names (`train2017/`, `val2017/`)
- Kaggle dataset might have flat structure or different naming

**Impact**:
- Training might fail with "file not found" errors
- Hard to debug because structure depends on Kaggle dataset version

**Fix Required**:
```python
# download_coco_dataset.py should:
# 1. Document Kaggle dataset structure
# 2. Reorganize files into expected structure
# 3. Create annotations/ folder with proper COCO JSON format
```

---

## ‚úÖ What Works Correctly

### Visual Genome ‚úÖ
- **Download**: `download_fiber_datasets.py` creates correct paths
- **Training**: `multi_dataset_loader.py` expects exactly those paths
- **Status**: **PERFECT MATCH** - will work without issues

### RefCOCO Annotations ‚úÖ
- **Download**: `download_fiber_datasets.py` downloads MDETR annotations correctly
- **Training**: `RefCOCODataset` expects exactly those paths
- **Status**: **ANNOTATIONS OK** - but images missing (see Issue #1)

---

## üîß Required Fixes

### Fix #1: Add COCO 2014 Download
**In**: `download_fiber_datasets.py`

```python
def download_coco_2014(self) -> bool:
    """Download COCO 2014 images for RefCOCO"""
    try:
        self.logger.info("üöÄ Downloading COCO 2014 images...")
        
        coco_dir = self.output_dir / "coco"
        coco_dir.mkdir(parents=True, exist_ok=True)
        
        urls = [
            ("http://images.cocodataset.org/zips/train2014.zip", "train2014.zip"),
            ("http://images.cocodataset.org/zips/val2014.zip", "val2014.zip"),
        ]
        
        for url, filename in urls:
            dest = coco_dir / filename
            if dest.exists():
                self.logger.info(f"‚úì {filename} already exists")
                continue
            
            self.logger.info(f"üì• Downloading {filename}...")
            subprocess.run(["curl", "-L", "-o", str(dest), url], check=True)
            self.logger.info(f"‚úì Downloaded {filename}")
            
            # Extract
            self.logger.info(f"üì¶ Extracting {filename}...")
            subprocess.run(["unzip", "-q", str(dest), "-d", str(coco_dir)], check=False)
            self.logger.info(f"‚úì Extracted {filename}")
        
        return True
    
    except Exception as e:
        self.logger.error(f"‚ùå COCO 2014 download failed: {e}")
        return False
```

### Fix #2: Update COCO Annotations Path
**In**: `src/multi_dataset_loader.py`

Add fallback to use `validated_coco.json`:

```python
# In COCOCaptionDataset.__init__()
if not ann_file.exists():
    # Fallback to validated_coco.json (from download_coco_dataset.py)
    fallback = self.data_root / "coco" / "validated_coco.json"
    if fallback.exists():
        print(f"Using validated COCO format: {fallback}")
        self._load_validated_format(fallback)
        return
    else:
        print(f"Warning: COCO annotations not found at {ann_file}")
        self.data = []
        return
```

### Fix #3: Standardize COCO Structure
**In**: `download_coco_dataset.py`

After download, reorganize to match expected structure:

```python
def standardize_structure(self):
    """Reorganize Kaggle download to match training expectations"""
    # Create expected folders
    (self.output_dir / "annotations").mkdir(exist_ok=True)
    (self.output_dir / "train2017").mkdir(exist_ok=True)
    (self.output_dir / "val2017").mkdir(exist_ok=True)
    
    # Move/organize files based on Kaggle structure
    # ... (implementation needed after understanding Kaggle structure)
```

---

## üìã Recommended Action Plan

### Immediate (Before Training):

1. **Test Current Downloads**:
   ```bash
   python download_coco_dataset.py
   python download_fiber_datasets.py
   ```

2. **Verify Actual Structures**:
   ```bash
   tree data/coco /F
   tree data/visual_genome /F
   tree data/mdetr_annotations /F
   ```

3. **Compare with Training Expectations**:
   - Check if COCO has `train2017/`, `val2017/`, `annotations/`
   - Check if COCO has `train2014/` (needed for RefCOCO)

### If Mismatches Found:

**Option A: Fix Download Scripts** (Recommended)
- Add COCO 2014 download to `download_fiber_datasets.py`
- Standardize COCO structure in `download_coco_dataset.py`
- Update both scripts to create expected folder structures

**Option B: Fix Training Code**
- Update `multi_dataset_loader.py` to handle multiple COCO formats
- Add fallback logic for different folder structures
- Document required manual reorganization steps

### Testing After Fixes:

```python
# Test multi-dataset loader
cd D:\BabyLM\BitGen
python src/multi_dataset_loader.py

# Should output:
# ‚úì Loaded XXXXX COCO train samples
# ‚úì Loaded XXXXX Visual Genome samples
# ‚úì Loaded XXXXX refcoco samples with bounding boxes
# ‚úì Loaded XXXXX VG region samples with bounding boxes
```

---

## üéØ Current Status Summary

| Dataset | Download Script | Training Code | Status |
|---------|----------------|---------------|--------|
| **COCO 2017** | `download_coco_dataset.py` | `COCOCaptionDataset` | ‚ö†Ô∏è Path mismatch |
| **COCO 2014** | ‚ùå Not downloaded | `RefCOCODataset` | üî¥ Missing |
| **Visual Genome** | `download_fiber_datasets.py` | `VisualGenomeCaptionDataset` | ‚úÖ Perfect |
| **VG Regions** | `download_fiber_datasets.py` | `VisualGenomeRegionDataset` | ‚úÖ Perfect |
| **RefCOCO** | `download_fiber_datasets.py` | `RefCOCODataset` | ‚ö†Ô∏è Images missing |
| **SBU** | Helper script only | Not implemented | ‚è∏Ô∏è Manual |
| **CC3M** | Helper script only | Not implemented | ‚è∏Ô∏è Manual |

---

## üí° Conclusion

**Will training work after downloads?**
- **Phase 1 (Coarse-Grained)**: ‚ö†Ô∏è **PARTIAL** - Visual Genome will work, COCO might fail
- **Phase 2 (Fine-Grained)**: üî¥ **NO** - RefCOCO will fail (missing COCO 2014 images)

**Recommended Next Step**:
Run both download scripts and verify actual folder structures, then implement Fix #1 (COCO 2014 download) and Fix #2 (COCO annotations fallback) before attempting training.
